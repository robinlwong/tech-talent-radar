{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "Here is the precise Python Script to optimize your 256MB dataset and generate the \"Killer Feature\" chart.\n",
        "\n",
        "Note: I attempted to run this on the file you uploaded (DS2F M1 Assignment Project Team), but it appears to be a PDF document (header %PDF-1.4), not a CSV. Please run the script below locally on your actual tech-talent-radar.csv file.\n",
        "\n",
        "The Optimization Strategy\n",
        "To get your file from 256MB down to <40MB, this script performs three actions:\n",
        "\n",
        "Filtering: Removes ~74% of rows by keeping only \"IT\" and \"Engineering\".\n",
        "\n",
        "Column Selection: Drops unused columns, keeping only what the dashboard needs.\n",
        "\n",
        "Compression: Saves the output as a .zip file, which Pandas handles automatically.\n",
        "\n",
        "Step 1: Save this code as optimize_data.py"
      ],
      "metadata": {
        "id": "bexjbg5OE8HH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import plotly.express as px\n",
        "\n",
        "# ==========================================\n",
        "# CONFIGURATION\n",
        "# ==========================================\n",
        "INPUT_FILE = \"tech_talent_radar.csv\"       # Your 256MB raw file\n",
        "OUTPUT_FILE = \"tech_talent_radar_opt.zip\"  # The optimized output file\n",
        "\n",
        "# Define your \"Killer Feature\" Keywords\n",
        "TECH_KEYWORDS = {\n",
        "    'Python': r'\\bpython\\b',\n",
        "    'Java': r'\\bjava\\b',\n",
        "    'React/JS': r'\\b(react|node|javascript|typescript|vue)\\b',\n",
        "    'Cloud/AWS': r'\\b(aws|azure|cloud|gcp)\\b',\n",
        "    'Data/AI': r'\\b(data|ai|machine learning|nlp|torch)\\b',\n",
        "    'Cybersecurity': r'\\b(cyber|security)\\b',\n",
        "    'DevOps': r'\\b(devops|sre|ci/cd)\\b',\n",
        "    '.NET/C#': r'\\b(\\.net|c#)\\b'\n",
        "}\n",
        "\n",
        "def clean_salary(val):\n",
        "    \"\"\"Parses salary strings (e.g., '$5,000') into floats.\"\"\"\n",
        "    try:\n",
        "        clean_str = re.sub(r'[^\\d.]', '', str(val))\n",
        "        return float(clean_str) if clean_str else np.nan\n",
        "    except:\n",
        "        return np.nan\n",
        "\n",
        "def get_tech_stack(title):\n",
        "    \"\"\"Scans title for keywords to assign a 'Stack'.\"\"\"\n",
        "    title = str(title).lower()\n",
        "    for stack, pattern in TECH_KEYWORDS.items():\n",
        "        if re.search(pattern, title):\n",
        "            return stack\n",
        "    return None  # Return None if no match found\n",
        "\n",
        "def process_dataset():\n",
        "    print(f\"üîÑ Loading {INPUT_FILE} (this may take a moment)...\")\n",
        "\n",
        "    # 1. Load Data\n",
        "    # low_memory=False handles mixed types in large files\n",
        "    df = pd.read_csv(INPUT_FILE, low_memory=False)\n",
        "\n",
        "    # 2. Filter for Target Sectors (IT & Engineering)\n",
        "    print(\"   Filtering for IT & Engineering...\")\n",
        "    target_sectors = ['Information Technology', 'Engineering']\n",
        "\n",
        "    # Ensure category column exists (adjust 'category' if your column is named 'industry')\n",
        "    if 'category' not in df.columns:\n",
        "        # Fallback for common column names\n",
        "        col = [c for c in df.columns if 'cat' in c.lower() or 'ind' in c.lower()][0]\n",
        "        print(f\"   Warning: 'category' column not found. Using '{col}' instead.\")\n",
        "        df.rename(columns={col: 'category'}, inplace=True)\n",
        "\n",
        "    # Apply Filter (Case Insensitive)\n",
        "    mask = df['category'].astype(str).str.lower().apply(\n",
        "        lambda x: any(s.lower() in x for s in target_sectors)\n",
        "    )\n",
        "    df_filtered = df[mask].copy()\n",
        "\n",
        "    print(f\"   ‚úÖ Row Count: {len(df)} -> {len(df_filtered)} (Reduced by {100 - int(len(df_filtered)/len(df)*100)}%)\")\n",
        "\n",
        "    # 3. Scan Titles (The \"Market Scan\")\n",
        "    print(\"\\nüìä Top 20 Most Common Titles (Use these to refine keywords):\")\n",
        "    print(df_filtered['job_title'].value_counts().head(20))\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    # 4. Clean Salaries & Tag Stacks\n",
        "    print(\"   Cleaning salaries and tagging skills...\")\n",
        "    # Normalize salary column names\n",
        "    if 'min_salary' in df_filtered.columns:\n",
        "        df_filtered.rename(columns={'min_salary': 'salary_min', 'max_salary': 'salary_max'}, inplace=True)\n",
        "\n",
        "    df_filtered['salary_min'] = df_filtered['salary_min'].apply(clean_salary)\n",
        "    df_filtered['salary_max'] = df_filtered['salary_max'].apply(clean_salary)\n",
        "    df_filtered['salary_avg'] = (df_filtered['salary_min'] + df_filtered['salary_max']) / 2\n",
        "\n",
        "    # Apply Keyword Tagging\n",
        "    df_filtered['Tech_Stack'] = df_filtered['job_title'].apply(get_tech_stack)\n",
        "\n",
        "    # 5. Build \"Stack vs Salary\" Chart\n",
        "    print(\"   Generating 'Stack vs Salary' Chart...\")\n",
        "    df_chart = df_filtered.dropna(subset=['salary_avg', 'Tech_Stack'])\n",
        "\n",
        "    if not df_chart.empty:\n",
        "        fig = px.box(df_chart, x='Tech_Stack', y='salary_avg',\n",
        "                     color='Tech_Stack',\n",
        "                     title=\"Tech Stack vs Salary (The Killer Feature)\",\n",
        "                     points=False) # Hide points to keep chart clean\n",
        "        fig.write_html(\"stack_vs_salary_chart.html\")\n",
        "        print(\"   ‚úÖ Chart saved as 'stack_vs_salary_chart.html'\")\n",
        "    else:\n",
        "        print(\"   ‚ö†Ô∏è Not enough data to generate chart.\")\n",
        "\n",
        "    # 6. Save Optimized File\n",
        "    print(f\"üíæ Saving optimized file to {OUTPUT_FILE}...\")\n",
        "\n",
        "    # Select only useful columns\n",
        "    cols_to_keep = ['job_title', 'company', 'category', 'salary_min', 'salary_max', 'salary_avg', 'date', 'Tech_Stack']\n",
        "    final_cols = [c for c in cols_to_keep if c in df_filtered.columns]\n",
        "\n",
        "    # Save as ZIP (This is the key step for file size)\n",
        "    df_filtered[final_cols].to_csv(OUTPUT_FILE, index=False, compression='zip')a\n",
        "    print(\"‚úÖ Success! You can now upload the .zip file to GitHub.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    process_dataset()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "v0plEFbfEOeo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Step 2: How to Run It**\n",
        "\n",
        "1. Make sure `tech_talent_radar.csv` is in the same folder as the script.\n",
        "2. Run `python optimize_data.py`.\n",
        "3. **Output:**\n",
        "* `tech_talent_radar_opt.zip`: This will be your small, dashboard-ready file.\n",
        "* `stack_vs_salary_chart.html`: Open this in your browser to see your \"Killer Feature\" immediately.\n",
        "* **Terminal Output:** It will print the Top 20 titles so you can see exactly what keywords to add next."
      ],
      "metadata": {
        "id": "9nn0xkdvEOep"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}