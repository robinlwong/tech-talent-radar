{"cells":[{"cell_type":"markdown","source":["# This is the final, end-to-end execution plan. I have updated both the **Data Processor** (to handle your specific JSON headers) and the **Streamlit Dashboard** (to match the new data structure).\n","\n","### **Step 1: Create `data_processor_v3.py**`\n","\n","This script converts your messy 1-million-row file into a clean, small ZIP file for the dashboard. It solves the \"empty fields\" issue by parsing the JSON categories correctly."],"metadata":{"id":"PNmxg_tw3Y4q"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import re\n","import json\n","\n","# ==========================================\n","# CONFIGURATION\n","# ==========================================\n","# 1. CHANGE THIS to your large file name\n","INPUT_FILE = \"tech_talent_radar.csv\"\n","OUTPUT_FILE = \"tech_talent_radar_final.zip\"\n","\n","# 2. Define Tech Stack Keywords (The Strategy Engine)\n","TECH_KEYWORDS = {\n","    'Python': r'\\bpython\\b',\n","    'Java': r'\\bjava\\b',\n","    'React/JS': r'\\b(react|node|javascript|typescript|vue|angular)\\b',\n","    'Cloud/AWS': r'\\b(aws|azure|cloud|gcp|google cloud)\\b',\n","    'Data/AI': r'\\b(data|ai|machine learning|nlp|torch|tensorflow|bi|tableau)\\b',\n","    'Cybersecurity': r'\\b(cyber|security|infosec)\\b',\n","    'DevOps': r'\\b(devops|sre|ci/cd|kubernetes|docker|jenkins)\\b',\n","    '.NET/C#': r'\\b(\\.net|c#|dotnet)\\b',\n","    'Civil/Struct': r'\\b(civil|structural|tunnel|bridge|geotechnical)\\b',\n","    'Mechanical': r'\\b(mechanical|hvac|piping|m&e)\\b',\n","    'Electrical': r'\\b(electrical|power|switchgear)\\b'\n","}\n","\n","def parse_categories(val):\n","    \"\"\"Extracts category names from JSON string.\"\"\"\n","    try:\n","        # Handle string representation of list\n","        if isinstance(val, str) and val.strip().startswith('['):\n","            # Safe eval or json load\n","            val = val.replace(\"'\", '\"') # Fix common quote issues\n","            data = json.loads(val)\n","            return [item.get('category', '') for item in data]\n","        return []\n","    except:\n","        return []\n","\n","def get_tech_stack(title):\n","    \"\"\"Scans title for keywords to assign a 'Stack'.\"\"\"\n","    title = str(title).lower()\n","    for stack, pattern in TECH_KEYWORDS.items():\n","        if re.search(pattern, title):\n","            return stack\n","    return None\n","\n","def clean_salary(val):\n","    try:\n","        return float(val)\n","    except:\n","        return np.nan\n","\n","def process():\n","    print(f\"üîÑ Loading {INPUT_FILE}...\")\n","    try:\n","        df = pd.read_csv(INPUT_FILE, low_memory=False)\n","    except FileNotFoundError:\n","        print(f\"‚ùå Error: Could not find {INPUT_FILE}. Please rename your large file.\")\n","        return\n","\n","    # 1. Filter for IT & Engineering (Using JSON parsing)\n","    print(\"   Parsing Categories & Filtering...\")\n","\n","    # Helper to filter rows\n","    def is_target(row_val):\n","        cats = parse_categories(row_val)\n","        return any(c in ['Information Technology', 'Engineering'] for c in cats)\n","\n","    mask = df['categories'].apply(is_target)\n","    df_filtered = df[mask].copy()\n","    print(f\"   ‚úÖ Filtered down to {len(df_filtered)} rows.\")\n","\n","    # 2. Rename Columns to Standard Names\n","    print(\"   Standardizing Columns...\")\n","    rename_map = {\n","        'title': 'job_title',\n","        'postedCompany_name': 'company',\n","        'metadata_newPostingDate': 'date',\n","        'average_salary': 'salary_avg',\n","        'salary_minimum': 'salary_min',\n","        'salary_maximum': 'salary_max'\n","    }\n","    df_filtered.rename(columns=rename_map, inplace=True)\n","\n","    # 3. Create 'category' column (Simple string for dashboard)\n","    def get_main_cat(val):\n","        cats = parse_categories(val)\n","        if 'Information Technology' in cats: return 'Information Technology'\n","        if 'Engineering' in cats: return 'Engineering'\n","        return 'Other'\n","    df_filtered['category'] = df_filtered['categories'].apply(get_main_cat)\n","\n","    # 4. Tag Tech Stacks\n","    print(\"   Tagging Tech Stacks...\")\n","    df_filtered['Tech_Stack'] = df_filtered['job_title'].apply(get_tech_stack)\n","\n","    # 5. Clean Salary\n","    for col in ['salary_min', 'salary_max', 'salary_avg']:\n","        if col in df_filtered.columns:\n","            df_filtered[col] = df_filtered[col].apply(clean_salary)\n","\n","    # Fill missing average if min/max exist\n","    mask = df_filtered['salary_avg'].isna()\n","    df_filtered.loc[mask, 'salary_avg'] = (df_filtered['salary_min'] + df_filtered['salary_max']) / 2\n","\n","    # 6. Save\n","    print(f\"üíæ Saving to {OUTPUT_FILE}...\")\n","    cols = ['job_title', 'company', 'category', 'salary_avg', 'date', 'Tech_Stack']\n","    # Filter for existing columns only\n","    final_cols = [c for c in cols if c in df_filtered.columns]\n","\n","    df_filtered[final_cols].to_csv(OUTPUT_FILE, index=False, compression='zip')\n","    print(\"‚úÖ Done! Ready for Dashboard.\")\n","\n","if __name__ == \"__main__\":\n","    process()"],"outputs":[],"execution_count":null,"metadata":{"id":"DI1sQzVl3Y4u"}},{"cell_type":"markdown","source":["---\n","\n","### **Step 2: Create `app.py` (The Dashboard)**\n","\n","This is the Streamlit app that reads the cleaned ZIP file."],"metadata":{"id":"QR_N_4LN3Y4v"}},{"cell_type":"code","source":["import streamlit as st\n","import pandas as pd\n","import plotly.express as px\n","\n","# PAGE CONFIG\n","st.set_page_config(page_title=\"Tech Talent Radar\", layout=\"wide\")\n","\n","# LOAD DATA\n","@st.cache_data\n","def load_data():\n","    # Load the compressed file directly\n","    df = pd.read_csv(\"tech_talent_radar_final.zip\")\n","    # Convert date\n","    if 'date' in df.columns:\n","        df['date'] = pd.to_datetime(df['date'], errors='coerce')\n","    return df\n","\n","try:\n","    df = load_data()\n","except FileNotFoundError:\n","    st.error(\"‚ùå Data file not found. Please run 'data_processor_v3.py' first!\")\n","    st.stop()\n","\n","# TITLE & SIDEBAR\n","st.title(\"üì° Tech & Engineering Talent Radar\")\n","st.markdown(\"### Competitive Intelligence for Singapore's Tech Sector\")\n","\n","with st.sidebar:\n","    st.header(\"Filters\")\n","    # Category Filter\n","    cats = df['category'].unique()\n","    selected_cat = st.radio(\"Select Sector:\", cats)\n","\n","    # Filter Data by Category first\n","    df_cat = df[df['category'] == selected_cat]\n","\n","    # Tech Stack Filter\n","    stacks = df_cat['Tech_Stack'].dropna().unique()\n","    selected_stacks = st.multiselect(\"Filter Tech Stacks:\", stacks, default=stacks[:5])\n","\n","# APPLY FILTERS\n","if selected_stacks:\n","    df_filtered = df_cat[df_cat['Tech_Stack'].isin(selected_stacks)]\n","else:\n","    df_filtered = df_cat\n","\n","# KPIS\n","c1, c2, c3 = st.columns(3)\n","c1.metric(\"Active Job Postings\", len(df_filtered))\n","avg_sal = df_filtered['salary_avg'].mean()\n","c2.metric(\"Avg Monthly Salary\", f\"${avg_sal:,.0f}\" if not pd.isna(avg_sal) else \"N/A\")\n","top_skill = df_filtered['Tech_Stack'].mode()[0] if not df_filtered.empty else \"N/A\"\n","c3.metric(\"Top In-Demand Skill\", top_skill)\n","\n","st.divider()\n","\n","# TABS\n","tab1, tab2, tab3 = st.tabs([\"üí∞ Value (Salary)\", \"üìà Demand (Volume)\", \"üè¢ Competition (Strategy)\"])\n","\n","with tab1:\n","    st.subheader(\"Which Tech Stack Pays the Most?\")\n","    if not df_filtered.empty:\n","        # Sort by median salary\n","        order = df_filtered.groupby('Tech_Stack')['salary_avg'].median().sort_values(ascending=False).index\n","        fig = px.box(df_filtered, x='Tech_Stack', y='salary_avg', color='Tech_Stack',\n","                     category_orders={'Tech_Stack': order}, points=False)\n","        st.plotly_chart(fig, use_container_width=True)\n","    else:\n","        st.info(\"Select Tech Stacks in the sidebar to see data.\")\n","\n","with tab2:\n","    st.subheader(\"Hiring Demand Over Time\")\n","    if 'date' in df_filtered.columns and not df_filtered['date'].isna().all():\n","        # Group by Month\n","        trend = df_filtered.groupby([pd.Grouper(key='date', freq='M'), 'Tech_Stack']).size().reset_index(name='Count')\n","        fig2 = px.line(trend, x='date', y='Count', color='Tech_Stack', markers=True)\n","        st.plotly_chart(fig2, use_container_width=True)\n","    else:\n","        st.warning(\"Date data is missing or invalid.\")\n","\n","with tab3:\n","    st.subheader(\"Top Companies Hiring for these Roles\")\n","    if not df_filtered.empty:\n","        top_companies = df_filtered['company'].value_counts().head(10).index\n","        df_top = df_filtered[df_filtered['company'].isin(top_companies)]\n","\n","        fig3 = px.histogram(df_top, y='company', color='Tech_Stack', barmode='stack')\n","        st.plotly_chart(fig3, use_container_width=True)"],"outputs":[],"execution_count":null,"metadata":{"id":"hxTST7M43Y4w"}},{"cell_type":"markdown","source":["---\n","\n","### **Step 3: Run Instructions (Execute EXACTLY in order)**\n","\n","1. **Prepare your Data File:**\n","* Take your original large file (`tech_talent_radar_sampleData...` or the 1M row file).\n","* **Rename it** to exactly: `tech_talent_radar.csv`\n","* Place it in a folder with `data_processor_v3.py` and `app.py`.\n","\n","\n","2. **Run the Processor:**\n","* Open your terminal/command prompt.\n","* Run: `python data_processor_v3.py`\n","* *Wait until it says \"‚úÖ Done!\". It will create `tech_talent_radar_final.zip`.*\n","\n","\n","3. **Run the Dashboard:**\n","* Run: `streamlit run app.py`\n","\n","\n","\n","This will launch your dashboard in the browser. It will now have accurate salaries, correct tech stacks (Python, Java, etc.), and working charts."],"metadata":{"id":"TF8u0rO73Y4x"}}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}